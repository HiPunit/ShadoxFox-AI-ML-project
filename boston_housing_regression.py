# -*- coding: utf-8 -*-
"""Boston_Housing_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkQ870wgx9t0IluHa5HGXae0I-gAB1Gr

# üè° Boston House Price Prediction using Regression
This notebook demonstrates how to build and evaluate regression models to predict housing prices using the Boston dataset.
"""

# Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# from sklearn.datasets import load_boston # This is removed in newer sklearn versions
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Step 2: Load the Dataset (fetching from original source as load_boston is removed)
data_url = "http://lib.stat.cmu.edu/datasets/boston"
raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]

# Define feature names based on the original dataset documentation
feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']

df = pd.DataFrame(data, columns=feature_names)
df['PRICE'] = target

df.head()

# Step 2: Load the Dataset - This cell is no longer needed as data loading is moved to Step 1.
# The data is now loaded in the previous cell and stored in the DataFrame 'df'.
# boston = load_boston()
# df = pd.DataFrame(boston.data, columns=boston.feature_names)
# df['PRICE'] = boston.target
# df.head()

# Step 3: Data Preprocessing - Check for missing values and statistics
print(df.isnull().sum())
print(df.describe())

# Price distribution
sns.histplot(df['PRICE'], kde=True)
plt.title('Price Distribution')
plt.show()

# Step 4: Correlation Matrix
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Feature Correlation')
plt.show()

# Step 5: Train-Test Split
X = df.drop('PRICE', axis=1)
y = df['PRICE']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Train Linear Regression Model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 7: Evaluate Linear Regression
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Linear Regression MSE:", mse)
print("Linear Regression R¬≤:", r2)

# Step 8: Try Decision Tree Regressor
from sklearn.tree import DecisionTreeRegressor
tree_model = DecisionTreeRegressor(random_state=42)
tree_model.fit(X_train, y_train)
tree_pred = tree_model.predict(X_test)
print("Decision Tree MSE:", mean_squared_error(y_test, tree_pred))
print("Decision Tree R¬≤:", r2_score(y_test, tree_pred))

# Step 9: Try Gradient Boosting Regressor
from sklearn.ensemble import GradientBoostingRegressor
gb_model = GradientBoostingRegressor()
gb_model.fit(X_train, y_train)
gb_pred = gb_model.predict(X_test)
print("Gradient Boosting MSE:", mean_squared_error(y_test, gb_pred))
print("Gradient Boosting R¬≤:", r2_score(y_test, gb_pred))